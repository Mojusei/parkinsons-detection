# src/models/train_model.py
from src.data.make_dataset import load_data, split_data
from src.models.train_pipeline import (
    train_and_evaluate,
    cross_validate_model,
    get_feature_importance
)
from src.visualization.visualize import (
    plot_confusion_matrix,
    plot_classification_report_heatmap,
    plot_feature_importance
)
from src.paths import ROOT_DIR, DATA_PATH, MODEL_PATH, FIGURES_DIR
from sklearn.metrics import classification_report
import joblib
import pandas as pd


def main() -> None:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å –ø–æ–ª–Ω–æ–π –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å—é.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ CLI: `poetry run train`.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç:
    - –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –Ω–∞ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ 80% –¥–∞–Ω–Ω—ã—Ö
    - –í—ã–≤–æ–¥ classification report –≤ –∫–æ–Ω—Å–æ–ª—å
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    """

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_data(DATA_PATH)
    X = df.drop(columns=["status"])
    y = df["status"]

    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cv_mean, cv_std = cross_validate_model(X, y, cv_folds=5)
    print(f"üîç –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (5-fold): {cv_mean:.2%} ¬± {cv_std:.2%}")

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ
    X_train, X_test, y_train, y_test = split_data(df)
    pipeline, test_acc, y_pred = train_and_evaluate(
        X_train,
        X_test,
        y_train,
        y_test
        )

    # Classification report (—Ç–µ–∫—Å—Ç–æ–≤—ã–π)
    print("\nüìã Classification Report:")
    print(classification_report(
        y_test,
        y_pred,
        target_names=["–ó–¥–æ—Ä–æ–≤", "–ë–æ–ª–µ–Ω"]
        ))

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    MODEL_PATH.parent.mkdir(exist_ok=True)
    joblib.dump(pipeline, MODEL_PATH)
    print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL_PATH}")
    print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {test_acc:.2%}")

    # Feature Importance
    feature_names = X.columns.tolist()
    importance = get_feature_importance(pipeline, feature_names)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤ CSV
    importance_df = pd.DataFrame(
        sorted(importance.items(), key=lambda x: x[1], reverse=True),
        columns=["–ü—Ä–∏–∑–Ω–∞–∫", "–í–∞–∂–Ω–æ—Å—Ç—å"]
    )
    importance_df.to_csv(
        ROOT_DIR / "reports" / "feature_importance.csv",
        index=False
        )
    print("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: reports/feature_importance.csv")

    # –ì—Ä–∞—Ñ–∏–∫–∏
    plot_confusion_matrix(
        y_test,
        y_pred,
        FIGURES_DIR / "confusion_matrix.png"
        )
    plot_classification_report_heatmap(
        y_test,
        y_pred,
        FIGURES_DIR / "classification_report.png"
        )
    plot_feature_importance(
        importance,
        top_n=15,
        save_path=FIGURES_DIR / "feature_importance.png"
        )


if __name__ == '__main__':
    main()
